# LLM Source Integration Plan

## Goal
Provide article source attribution generated by an LLM, store it alongside summaries, and surface it in export briefs.

## Constraints & Inputs
- Reuse existing SiliconFlow API credentials; new model name comes from `SOURCE_MODEL_NAME` env var.
- Preserve current behaviour as fallback when LLM inference fails or data is missing.
- Avoid breaking existing pipelines; keep summary generation resilient.

## Work Breakdown
1. **Configuration** (done)
   - Extend `Settings` to expose `source_model_name` with default fallback.
   - Document the new variable in `.env.local.example` if available.
2. **LLM Client** (done)
   - Add `src/adapters/llm_source.py` mirroring retry/backoff logic from `llm_summary`, but prompting for source extraction from `content_markdown`.
   - Return cleaned source string plus raw API payload for auditing.
3. **Summarize Worker Integration** (done)
   - After summary generation, invoke the new client per article.
   - Swallow client failures with logging and proceed; attach the result to DB writes via `llm_source`.
4. **Persistence Layer** (done)
   - Database: add `llm_source` (text, nullable) to `news_summaries` and propagate to migrations / Supabase schema notes.
   - Update adapters (`save_summary`, `upsert_news_summary`, Supabase equivalents) to read/write the field and keep `processed_payload[llm_source]` for compatibility.
   - Ensure `fetch_export_candidates` selects the column and maps it to `ExportCandidate.llm_source`.
5. **Exporter Update** (done)
   - Prefer `llm_source` in export formatting, fall back to existing `source`.
   - Reflect preference in Feishu notifications if necessary.
6. **Testing & Verification**
   - Add unit coverage for the new adapter client (prompt shape, retry behaviour).
   - Extend worker tests to assert DB writes include `llm_source` when mocked.
   - Add regression for exporter choosing the LLM-derived source.
7. **Operational Notes**
   - Provide instructions for setting `SOURCE_MODEL_NAME` and running migrations.
   - Monitor logs for fallback rate once deployed.

## Open Questions
- Is there a canonical list for source normalization? If so, integrate clean-up before persistence.
- Do we need to backfill existing rows with LLM sources, or only handle new entries?







