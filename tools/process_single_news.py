#!/usr/bin/env python3
"""
å¿«é€Ÿå¤„ç†å•ä¸ªæ–°é—»é“¾æ¥çš„è„šæœ¬ï¼š
1. æ¥æ”¶æ–°é—»é“¾æ¥
2. è°ƒç”¨ toutiao_fetch.py è·å–å†…å®¹å¹¶ä¿å­˜åˆ°æ•°æ®åº“
3. è°ƒç”¨ summarize_news.py ç”Ÿæˆæ‘˜è¦
4. è·³è¿‡è¯„åˆ†é˜¶æ®µ
5. ç›´æ¥è¾“å‡º titleã€summaryã€source_LLM åˆ°æ§åˆ¶å°
"""

import argparse
import re
import sqlite3
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Optional, Dict, Any

# é¡¹ç›®æ ¹ç›®å½•å’Œå·¥å…·ç›®å½•
REPO_ROOT = Path(__file__).resolve().parents[1]
TOOLS_DIR = REPO_ROOT / "tools"
DEFAULT_DB_PATH = REPO_ROOT / "articles.sqlite3"
DEFAULT_KEYWORDS_PATH = REPO_ROOT / "education_keywords.txt"

def fetch_news_to_db(url: str, db_path: Path) -> Optional[str]:
    """
    ä½¿ç”¨ toutiao_fetch.py è·å–æ–°é—»å¹¶ä¿å­˜åˆ°æ•°æ®åº“
    è¿”å› article_id å¦‚æœæˆåŠŸï¼Œå¦åˆ™è¿”å› None
    """
    try:
        # è°ƒç”¨ toutiao_fetch.py
        cmd = [
            sys.executable,
            str(TOOLS_DIR / "toutiao_fetch.py"),
            url,
            "--db", str(db_path),
            "--format", "json"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True, cwd=REPO_ROOT, encoding='utf-8', errors='replace')

        if result.returncode != 0:
            print(f"Error fetching news: {result.stderr}", file=sys.stderr)
            return None

        # ä»æ•°æ®åº“ä¸­è·å–åˆšæ’å…¥çš„æ–‡ç« ID
        conn = sqlite3.connect(db_path)
        try:
            cur = conn.cursor()
            cur.execute("SELECT article_id FROM articles ORDER BY id DESC LIMIT 1")
            row = cur.fetchone()
            return row[0] if row else None
        finally:
            conn.close()

    except Exception as e:
        print(f"Error in fetch_news_to_db: {e}", file=sys.stderr)
        return None

def generate_summary(article_id: str, db_path: Path, keywords_path: Path) -> bool:
    """
    ä½¿ç”¨ summarize_news.py ä¸ºæŒ‡å®šæ–‡ç« ç”Ÿæˆæ‘˜è¦
    """
    try:
        # è°ƒç”¨ summarize_news.pyï¼Œé™åˆ¶åªå¤„ç†è¿™ä¸€ç¯‡æ–‡ç« 
        cmd = [
            sys.executable,
            str(TOOLS_DIR / "summarize_news.py"),
            "--db", str(db_path),
            "--keywords", str(keywords_path),
            "--limit", "1"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True, cwd=REPO_ROOT, encoding='utf-8', errors='replace')

        if result.returncode != 0:
            print(f"Error generating summary: {result.stderr}", file=sys.stderr)
            return False

        return True

    except Exception as e:
        print(f"Error in generate_summary: {e}", file=sys.stderr)
        return False

def get_news_data(article_id: str, db_path: Path) -> Optional[Dict[str, Any]]:
    """
    ä»æ•°æ®åº“ä¸­è·å–å¤„ç†åçš„æ–°é—»æ•°æ®
    """
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        try:
            cur = conn.cursor()
            cur.execute(
                "SELECT title, summary, source, source_LLM FROM news_summaries WHERE article_id = ?",
                (article_id,)
            )
            row = cur.fetchone()
            if row:
                return {
                    "title": row["title"] or "",
                    "summary": row["summary"] or "",
                    "source": row["source"] or "",
                    "source_LLM": row["source_LLM"] or ""
                }
            return None
        finally:
            conn.close()
    except Exception as e:
        print(f"Error getting news data: {e}", file=sys.stderr)
        return None

def extract_url_from_paste(paste_content: str) -> Optional[str]:
    """
    ä»ç²˜è´´å†…å®¹ä¸­æå–ä»Šæ—¥å¤´æ¡é“¾æ¥
    æ”¯æŒæ ¼å¼å¦‚ï¼šhttps://m.toutiao.com/is/YEexSWXbGwQ/
    """
    # åŒ¹é…ä»Šæ—¥å¤´æ¡é“¾æ¥çš„æ­£åˆ™è¡¨è¾¾å¼
    patterns = [
        r'https?://m\.toutiao\.com/is/[A-Za-z0-9]+/?',
        r'https?://www\.toutiao\.com/article/\d+/?',
        r'https?://m\.toutiao\.com/i\d+/?',
        r'https?://[^/]*toutiao\.com[^\s]*',
        r'https?://[^/]*bjd\.com\.cn[^\s]*'  # æ”¯æŒåŒ—äº¬æ—¥æŠ¥ç½‘
    ]

    for pattern in patterns:
        match = re.search(pattern, paste_content)
        if match:
            return match.group(0)

    return None

def interactive_input() -> Optional[str]:
    """
    äº¤äº’å¼è·å–æ–°é—»é“¾æ¥
    """
    print("è¯·ç²˜è´´æ–°é—»åˆ†äº«å†…å®¹ï¼ˆåŒ…å«é“¾æ¥ï¼‰ï¼š")
    print("ä¾‹å¦‚ï¼šã€AIèµ‹èƒ½ï½¤äººäººå‚ä¸!åŒ—äº¬å¸‚2025å¹´åŒ—äº¬å¸‚ä¸­å°å­¦ç§‘å­¦èŠ‚(é€š... - ä»Šæ—¥å¤´æ¡ã€‘")
    print("ç‚¹å‡»é“¾æ¥æ‰“å¼€ğŸ‘‰ https://m.toutiao.com/is/YEexSWXbGwQ/")
    print("æŒ‰ Ctrl+C é€€å‡º")
    print("-" * 50)

    try:
        # è¯»å–å¤šè¡Œè¾“å…¥ç›´åˆ°ç©ºè¡Œ
        lines = []
        while True:
            try:
                line = input()
                if not line.strip():  # ç©ºè¡Œè¡¨ç¤ºç»“æŸ
                    break
                lines.append(line)
            except EOFError:  # Ctrl+D
                break

        paste_content = "\n".join(lines)
        if not paste_content.strip():
            print("æ²¡æœ‰è¾“å…¥å†…å®¹ï¼Œé€€å‡ºã€‚")
            return None

        # æå–é“¾æ¥
        url = extract_url_from_paste(paste_content)
        if url:
            print(f"\næå–åˆ°çš„é“¾æ¥: {url}")
            return url
        else:
            print("\næœªèƒ½ä»è¾“å…¥ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„æ–°é—»é“¾æ¥")
            return None

    except KeyboardInterrupt:
        print("\nç”¨æˆ·å–æ¶ˆï¼Œé€€å‡ºã€‚")
        return None

def print_news_output(data: Dict[str, Any]) -> None:
    """
    æŒ‰ç…§ export_high_correlation.py çš„æ ¼å¼è¾“å‡ºæ–°é—»
    """
    title = data["title"].strip()
    summary = data["summary"].strip()
    source_llm = data["source"].strip()

    # æŒ‰ç…§ export_high_correlation.py:109 çš„æ ¼å¼
    suffix = f" ({source_llm})" if source_llm else ""
    output = f"{title}\n{summary}{suffix}"

    print(output)

def main() -> int:
    parser = argparse.ArgumentParser(description="Process a single news URL")
    parser.add_argument("url", nargs="?", help="æ–°é—»é“¾æ¥URLï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è¿›å…¥äº¤äº’æ¨¡å¼ï¼‰")
    parser.add_argument("--db", type=Path, default=DEFAULT_DB_PATH, help="SQLite æ•°æ®åº“è·¯å¾„")
    parser.add_argument("--keywords", type=Path, default=DEFAULT_KEYWORDS_PATH, help="å…³é”®è¯æ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    db_path = args.db.resolve()
    keywords_path = args.keywords.resolve()

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    if not keywords_path.exists():
        print(f"Error: Keywords file not found: {keywords_path}", file=sys.stderr)
        return 1

    # è·å–URLï¼šä»å‘½ä»¤è¡Œå‚æ•°æˆ–äº¤äº’å¼è¾“å…¥
    url = args.url
    if not url:
        url = interactive_input()
        if not url:
            return 1

    print("Step 1: Fetching news content...", file=sys.stderr)
    article_id = fetch_news_to_db(url, db_path)
    if not article_id:
        print("Failed to fetch news content", file=sys.stderr)
        return 1

    print(f"Step 2: Generating summary for article {article_id}...", file=sys.stderr)
    if not generate_summary(article_id, db_path, keywords_path):
        print("Failed to generate summary", file=sys.stderr)
        return 1

    print("Step 3: Retrieving processed data...", file=sys.stderr)
    news_data = get_news_data(article_id, db_path)
    if not news_data:
        print("Failed to retrieve processed news data", file=sys.stderr)
        return 1

    # è¾“å‡ºç»“æœåˆ°æ§åˆ¶å°
    print("=" * 50, file=sys.stderr)
    print_news_output(news_data)

    return 0

if __name__ == "__main__":
    sys.exit(main())