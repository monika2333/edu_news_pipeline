0110_early_cluster.md
请阅读文档，指出它的问题


问题

高: 0110_early_cluster.md (line 51) 仅写“执行聚类算法”，但未定义算法类型、相似度/阈值、执行位置（DB/worker），pgvector 只提供向量检索，缺少聚类实现细节导致方案不可落地。
高: 0110_early_cluster.md (line 31) 表只存 item_ids 与 representative_title，未说明如何返回前端所需的完整 item 字段与排序规则；0110_early_cluster.md (line 66) 的接口也与现有 /api/manual_filter/candidates?cluster=true 不一致，落地会破坏当前 UI 调用链。
中: 0110_early_cluster.md (line 28) 选择 vector_l2_ops 与当前标题聚类的 cosine 相似度不一致；0110_early_cluster.md (line 24) 的 1024 维未说明与实际 embedding 模型一致性，否则阈值和索引语义会偏差。
中: 0110_early_cluster.md (line 16), 0110_early_cluster.md (line 57) 假设在 manual_reviews 入库时可计算标题向量，但该表不含标题字段，缺少从 news_summaries 取值/回填与更新策略。
中: 0110_early_cluster.md (line 18), 0110_early_cluster.md (line 52), 0110_early_cluster.md (line 59) 仅基于 pending 且 5 分钟刷新，全量替换会造成已处理项短时滞留，且未覆盖当前“ready_for_export”筛选条件。
低: 0110_early_cluster.md (line 5), 0110_early_cluster.md (line 6) 痛点描述缺少基准数据与现状验证（已有内存缓存/多 worker 情况），建议先量化瓶颈再决定重构力度。
待确认

目标 embedding 模型是否仍为 BGE，维度与是否归一化是否固定？
聚类结果是否必须保持现有 /api/manual_filter/candidates 的响应结构与字段？
允许的展示延迟到底是分钟级还是需要用户操作后即时剔除？
聚类实现希望落在 DB（SQL/存储过程）还是后台 worker（Python）？
我觉得embedding继续保持BGE即可，或者你有更好的建议吗？我不确定“维度与是否归一化是否固定”，请给你你的判断
聚类结果并非必须保持现有结构和字段，好用即可，请给出你的判断
“允许的展示延迟到底是分钟级还是需要用户操作后即时剔除？”这个我不确定，请给出你的判断
目前的聚类是用worker python 实现的吧？沿用目前的即可
此外，关于你提到的几个问题，我们也需要依次解决一下，请判断哪些是你自己可以决定的，哪些是需要我参与讨论的。
暂时不需要修改文档，请继续和我讨论即可。


答复按你的 4 点来：

继续用 BGE 没问题，当前实现是 BAAI/bge-large-zh，输出维度是 1024，且在编码时已做归一化（normalize_embeddings=True）。只要模型不换，维度与归一化就是“固定”的。
如果要更快、成本更低，可以考虑 bge-base-zh/bge-small-zh（维度会变，阈值需要重新调）；如果要多语种再考虑 bge-m3。就目前场景，我建议继续 bge-large-zh。

不必保持现有结构时，我的判断是：仍然返回“可直接渲染的最小卡片字段”会最好用，避免再打一次详情接口。推荐字段：
cluster_id, report_type, bucket_key, size, representative_title, items[{article_id,title,summary,score,source,url,status,external_importance_score,is_beijing_related,sentiment_label}]。
为了控制体积，可只返回前 N 条 items + item_ids，展开时再拉详情。

我建议“用户操作后立即剔除”，后台聚类可以分钟级刷新。实现上可以：

查询时过滤非 pending（即使聚类结果有滞后）；或
触发决定后对缓存/表做增量 prune。
这样既不牺牲 UX，也能保持预聚类的性能收益。
目前聚类是在控制台服务进程内的 Python 逻辑执行（请求触发、内存缓存），不是独立 worker。沿用 Python 实现是可行的；如果要定时跑，就把这段逻辑挪到 worker 即可。
我可以自行决定的：

模型与向量细节：继续 bge-large-zh、维度 1024、归一化、cosine 相似度与阈值初值（0.9）。
聚类算法与实现位置：沿用当前 Python 聚类逻辑，必要时下放到 worker。
索引与相似度算子匹配（若启用 pgvector 检索）。
需要你参与确认的：

UX 延迟策略：必须“立即剔除”还是“分钟级可接受”？
API 返回结构与体量：一次性返回所有 items 还是“前 N + 详情”？
刷新策略：固定周期、手动触发、或两者都要？
如果你同意我的判断，我就按下面两点推进设计细化，继续和你对齐：

立即剔除 + 分钟级后台刷新
返回可直接渲染的最小卡片字段（必要时 N 条 + 详情）
UX 延迟策略：“立即剔除”还是“分钟级可接受”好处和坏处分别是什么？你前面已经提到过可以用户操作后立即剔除（我同意你的观点），和这个有关系吗？
API 返回结构与体量：一次性返回所有 items 还是“前 N + 详情”，这两种区别和优劣是什么呢？目前我感觉前台通常看到的也就是500条以内的新闻，一次性返回来应该也压力不大吧？
刷新策略：两者都要

延迟策略

“立即剔除”优点：体验一致（用户操作后列表立刻变）、避免重复处理、减少困惑；缺点：需要做缓存/聚类结果的增量更新或读取时过滤，逻辑更复杂，涉及并发一致性处理。
“分钟级可接受”优点：实现简单、批量更新负载稳定；缺点：前台会看到已处理项、可能重复决策、需要提示“最后更新时间”，也需要读时过滤非 pending 才能避免错误。
两者关系：立即剔除是对分钟级刷新带来的“过期数据”的补偿，二者是互补的；你同意立即剔除的观点就等于认可“分钟级刷新 + 实时增量剔除”的组合。
API 返回结构与体量

一次性返回所有 items：优点是最简单、一次请求即可渲染；缺点是 payload 与渲染负担随着数据上涨，尤其是 summary/内容字段较大时会影响首屏。
“前 N + 详情”：优点是首屏快、可扩展；缺点是多接口和前端状态复杂，排序与一致性处理更麻烦。
结合你说的“<=500条”：我判断一次性返回是可行的，但建议加保护措施：限制上限（比如 500/1000），并避免返回大字段（如全文/markdown），这样不会明显有压力。
刷新策略

两者都要没问题：定时刷新（如 5 分钟）+ 手动触发 + 操作后即时剔除（缓存或读时过滤），并返回 refreshed_at 给前端提示。
如果你认可上面的判断，我可以继续把“立即剔除 + 分钟级刷新 + 全量返回上限”这套策略细化到实现层面的流程建议。

ok就按你说的来。目前我的系统本来就是返回summary，没有全文。

请继续判断，目前的方案还有什么漏洞


好的，按“分钟级刷新 + 用户操作后立即剔除 + summary-only 全量返回”的方向，当前方案还有这些漏洞/空点需要补齐：

剩余漏洞与待确认点

性能/复杂度：如果仍是两两相似度的 O(n^2) 聚类，n 上到 5000 仍会很重；需要你确认每个 report_type + bucket 的最大规模与可接受的刷新耗时，否则无法决定是否引入 ANN/分批。
多进程一致性：如果 Web 与 worker 多实例部署，任何内存缓存或“即时剔除”只在单进程生效；要么完全以 DB 结果为准、禁用本地缓存，要么加分布式缓存/消息。需要你确认部署形态。
标题/向量生命周期：如果标题会被修订（或从不同来源再清洗），旧 embedding 会漂移；需要你确认标题是否会变更，决定是否重算/加触发器。
过滤条件一致性：方案仅写 pending，但当前查询还依赖 ready_for_export 和 report_type；不补齐会混入未达标数据。我可以直接决定与现有筛选保持一致。
结果版本管理：不存 refreshed_at、cluster_threshold、model_name/version，以后阈值或模型变更会导致结果不可追溯。我可以决定在结果表或 meta 表里补上。
即时剔除落地：如果只存 item_ids，用户决策后要么重算整个簇，要么读时 join/filter；两者的性能和实现复杂度不同，需要你确认更偏向“写时维护”还是“读时过滤”。
如果你能补充这三点，我就能把方案细化到可执行层面：

每个 bucket 的最大规模/刷新 SLA
是否多进程/多实例部署
标题是否可能更新（如果会，是否允许后台重算）
我觉得目前的聚类就蛮好用，在聚类逻辑和判断方面不需要有任何修改
完全以 DB 结果为准、禁用本地缓存
目前标题不会变更，所以不必担心
ok直接与现有筛选保持一致即可
结果版本管理：目前我暂时不打算更换模型和调整参数，这个是不是可以暂时不存？
读时过滤更简单吧？选这个吧

按你现在的选择，方案可以定为：保留现有聚类算法与阈值，后台定时+手动刷新写入 DB，API 只从 DB 读并在读时过滤非 pending，前端只展示 summary。

剩余漏洞/空点

读时过滤会让 size/representative 过期：某些条目被剔除后，原“代表标题”可能已不在 pending，size 也不准；建议读时重算 size 与 representative（用过滤后的首条）。
刷新原子性与并发：TRUNCATE/DELETE + INSERT 会阻塞读或短暂空表；需要“staging 表 + 交换”或“事务内整体替换”，并加任务锁防并发刷新。
数据模型不闭合：manual_clusters 如果只存 item_ids，读时需要 unnest + join 才能拿到 summary/source 等字段，SQL 与性能复杂度上升；需要决定存 item_ids 还是直接存 items 的 jsonb 快照。
失败回滚：刷新失败时不能覆盖旧结果，否则前端无数据；需要明确“写入成功才替换”。
pgvector/embedding 价值：若算法不改且不使用向量检索，title_embedding 暂时没有收益；可以先不加或只为未来预留。
我可以直接决定并落地的

读时重算 size 和 representative，保证用户操作后立刻正确。
统计数据从 manual_reviews 现状计算，不依赖聚类表，确保“立即剔除”一致。
加任务锁与“成功后替换”的刷新策略。
需要你选一下的

manual_clusters 存储形态：
item_ids（读时 join，表小，但查询复杂）
items jsonb（读快、结构直观，但表大、写入重）
是否现在就加 title_embedding 字段（即便暂时不使用）：
先不加，避免无效字段
预留字段，未来可以直接切到向量检索
刷新间隔是否就按 5 分钟（文档默认）？
你拍板这 3 点，我就可以把剩下的实现细节也定下来。

关于item_ids或者items jsonb，你更推荐哪个？
先不加title_embedding，避免无效字段
刷新间隔就按5分钟

我更推荐 item_ids。
理由是你已经明确“以 DB 为准、读时过滤、summary 可能编辑”，items jsonb 会更容易出现数据陈旧（summary/状态/编辑内容不实时），而 item_ids 读时 join 可以始终拿到最新数据并按当前 pending 状态过滤。代价是查询更复杂，但你说量级在 500 左右，这个成本是可接受的。

对比一下：

item_ids：数据最新、过滤准确、存储小；缺点是读时要 join + regroup。
items jsonb：读接口最简单；缺点是容易陈旧、过滤要再校验、存储更大。
我建议：选 item_ids，读时按现有排序规则重建 cluster（保持和现在聚类逻辑一致）。

确认你同意后，我可以继续细化两块内容：

聚类表结构 + 读时查询/重组流程
API 返回结构（最小字段集合 + 排序方式）
ok就按你说的，用item_ids吧。请继续细化


好的，按你的选择我把方案细化到“可落地”的结构与流程，保持现有聚类算法不变、仅改为 DB 预计算 + 读时过滤。

1) 表结构（manual_clusters）

report_type text not null
bucket_key text not null（internal_positive / internal_negative / external_positive / external_negative）
cluster_id text not null（建议 "{bucket_key}-{index}" 或 "{report_type}-{bucket_key}-{index}"，避免跨报型冲突）
item_ids text[] not null
created_at timestamptz default now()
updated_at timestamptz default now()
索引建议：
(report_type, bucket_key)
(可选) item_ids 的 GIN 索引，若未来需要按 article_id 反查
你不打算变更模型/阈值，model_name/version 可以先不存；但建议保留 updated_at 用于前端“最后更新时间”。

2) 刷新流程（5 分钟 + 手动触发）

定时任务/手动触发共用同一刷新函数
先拿 advisory lock，避免并发刷新
对每个 report_type：
用现有筛选拉全量 pending：manual_reviews.status='pending' 且 news_summaries.status='ready_for_export'
按 is_beijing_related + sentiment_label 分 4 桶
每桶用现有 BGE + 阈值 0.9 聚类
每个 cluster 内按当前排序规则（external_importance_score, score, publish_time）排序
写入 item_ids
写入策略：DELETE FROM manual_clusters WHERE report_type = ?，再批量 INSERT，都放在同一事务中，失败回滚保留旧数据（不要 TRUNCATE）
3) 读时过滤 + 重建 cluster

API 读取流程：
按 report_type + bucket_key 读出 clusters
展开 item_ids，join manual_reviews + news_summaries
过滤 pending + ready_for_export
对每个 cluster：
重新计算 size
用过滤后的首条作为 representative_title
items 按现有 rank 规则排序
过滤后为空的 cluster 丢弃
过滤后再分页，避免出现“分页空洞”
4) API 返回结构（summary-only，适配现有前端）

clusters:
cluster_id, report_type, bucket_key, size, representative_title
items: article_id, title, summary, source, url, score, external_importance_score, is_beijing_related, sentiment_label, llm_source_display, llm_source_raw, llm_source_manual, bonus_keywords
total（过滤后的 cluster 总数）
refreshed_at（manual_clusters.updated_at 的 max，可用于“最后更新时间”）
5) 立即剔除的实现

不依赖本地缓存，读时过滤 pending 即可实现“操作后立即剔除”。
前端无需改逻辑，只要刷新列表就会看到最新状态。
6) 重要边界

若 cluster 的代表条目被剔除，读时会自动切换为新的 representative
手动编辑 summary 会立刻体现在列表中（因为 join 实时取最新值）
负载可控：你说量级 <= 500，读时聚合和排序不会成为瓶颈
如果你认可这个细化方案，我可以继续把以下两个部分做成实现建议（不改文档也行）：

具体 SQL/Adapter 查询结构（含 unnest + join）
后台刷新 worker 的伪代码流程与边界处理
ok go on


Read Path

读时按 report_type + bucket_key 取 item_ids，再 join manual_reviews + news_summaries，过滤 pending + ready_for_export，然后在 Python 里按现有排序规则重建 items、size 与 representative_title，最后再分页（避免分页空洞）。
SQL 骨架（示例，report_type 的默认值建议沿用 adapter 的 _report_type_expr 逻辑）：
WITH cluster_base AS (
    SELECT cluster_id, bucket_key, item_ids, updated_at
    FROM manual_clusters
    WHERE report_type = $1
      AND ($2::text IS NULL OR bucket_key = $2)
),
cluster_items AS (
    SELECT cb.cluster_id,
           cb.bucket_key,
           cb.updated_at,
           unnest(cb.item_ids) AS article_id
    FROM cluster_base cb
)
SELECT
    ci.cluster_id,
    ci.bucket_key,
    ci.updated_at,
    mr.article_id,
    mr.status AS manual_status,
    mr.summary AS manual_summary,
    mr.rank AS manual_rank,
    COALESCE(mr.report_type, 'zongbao') AS report_type,
    ns.title,
    ns.llm_summary,
    ns.llm_source,
    ns.source,
    ns.url,
    ns.score,
    ns.external_importance_score,
    ns.sentiment_label,
    ns.is_beijing_related,
    ns.publish_time_iso,
    ns.publish_time,
    ns.score_details
FROM cluster_items ci
JOIN manual_reviews mr ON mr.article_id = ci.article_id
JOIN news_summaries ns ON ns.article_id = ci.article_id
WHERE mr.status = 'pending'
  AND ns.status = 'ready_for_export'
ORDER BY ci.cluster_id,
         ns.external_importance_score DESC NULLS LAST,
         mr.rank ASC NULLS LAST,
         ns.score DESC NULLS LAST,
         ns.publish_time_iso DESC NULLS LAST,
         mr.article_id ASC;
refreshed_at 可以用：SELECT MAX(updated_at) FROM manual_clusters WHERE report_type = $1.
Write Path

定时/手动共用刷新函数，先拿 advisory lock，避免并发跑。
流程伪代码（复用现有聚类算法，不改逻辑）：
def refresh_clusters(report_type: str) -> None:
    if not adapter.try_advisory_lock("manual_cluster_refresh"):
        return

    rows = adapter.fetch_manual_pending_for_cluster(
        report_type=report_type,
        region=None,
        sentiment=None,
        fetch_limit=5000,
    )

    buckets = bucket_by_region_and_sentiment(rows)  # internal/external + positive/negative
    clusters = []
    for bucket_key, items in buckets.items():
        if not items:
            continue
        items_sorted = sorted(items, key=_candidate_rank_key_by_record, reverse=True)
        titles = [i.get("title") or "" for i in items_sorted]
        groups = cluster_titles(titles, threshold=0.9) or [list(range(len(items_sorted)))]

        for idx, group in enumerate(groups):
            group_items = [items_sorted[i] for i in group]
            if not group_items:
                continue
            group_items.sort(key=_candidate_rank_key_by_record, reverse=True)
            clusters.append({
                "cluster_id": f"{report_type}-{bucket_key}-{idx}",
                "report_type": report_type,
                "bucket_key": bucket_key,
                "item_ids": [i["article_id"] for i in group_items],
            })

    with adapter.transaction():
        adapter.delete_manual_clusters(report_type=report_type)
        adapter.insert_manual_clusters(clusters)

    adapter.release_advisory_lock("manual_cluster_refresh")
失败回滚要保证“旧数据仍在”，所以必须事务内 delete+insert。
空结果也要 delete，避免前端看到旧集群。
Adapter 要点（不改代码也能先对齐）

delete_manual_clusters(report_type)
insert_manual_clusters(clusters: list[dict])
fetch_manual_clusters(report_type, bucket_key=None) + join 读时过滤（SQL 如上）
advisory lock：pg_try_advisory_lock(hashtext('manual_cluster_refresh'))
如果你点头，我可以把这套流程进一步映射到当前的 adapter/console 结构（具体函数名与复用位置），并标出需要新增的 minimal API。